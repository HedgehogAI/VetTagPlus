CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/sage_lm --gpu_id 0 --n_epochs 15 --no_stop --train_emb --tied --d_ff 2048 --n_heads 8 --n_layers 6 --batch_size 32 --hypes hypes/default.json

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/sage_lm_lstm --gpu_id 0 --n_epochs 30 --no_stop --train_emb --tied --d_ff 2048 --n_heads 8 --n_layers 6 --bptt_size 30 --batch_size 32 --hypes hypes/default.json

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/sage_lm_no_bpe --gpu_id 0 --n_epochs 15 --no_stop --train_emb --tied --d_ff 2048 --n_heads 8 --n_layers 6 --batch_size 32 --hypes hypes/default.json

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/wiki_lm --gpu_id 0 --n_epochs 15 --no_stop --train_emb --tied --d_ff 2048 --n_heads 8 --n_layers 6 --batch_size 32 --bptt_size 100 --hypes hypes/wiki.json

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/wiki103_lm --gpu_id 0 --n_epochs 15 --no_stop --train_emb --tied --d_ff 2048 --n_heads 8 --n_layers 6 --batch_size 32 --bptt_size 50 --hypes hypes/wiki103.json

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/wiki103_lm_lstm --gpu_id 0 --n_epochs 15 --no_stop --train_emb --tied --d_ff 2048 --n_heads 8 --n_layers 6 --batch_size 32 --bptt_size 50 --hypes hypes/wiki103.json --model_type lstm

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/csu_test  --no_stop --train_emb --tied --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/pp_test  --no_stop --train_emb --tied --corpus pp --hypes hypes/pp.json --batch_size 10 --proj_head 4 --model_type transformer

#0728

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu_lstm_cut600  --no_stop --train_emb --tied --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/csu_transformer_cut600 --no_stop --train_emb --tied --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_transformer_cut600_bs4 --no_stop --train_emb --tied --corpus csu --hypes hypes/csu.json --batch_size 4 --proj_head 4 --model_type transformer --cut_down_len 600

#0729

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/pp_test  --no_stop --train_emb --tied --corpus pp --hypes hypes/pp.json --batch_size 10 --proj_head 4 --model_type transformer --inputdir exp/csu_transformer_cut600/model-8.pickle --cut_down_len 600

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/pp_test  --no_stop --train_emb --tied --corpus pp --hypes hypes/pp.json --batch_size 10 --proj_head 4 --model_type transformer --inputdir exp/csu_lstm_cut600/model-15.pickle --cut_down_len 600

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_test  --no_stop --train_emb --tied --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type transformer --inputdir exp/csu_transformer_cut600/model-8.pickle --cut_down_len 600

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_test  --no_stop --train_emb --tied --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type transformer --inputdir exp/csu_lstm_cut600/model-15.pickle --cut_down_len 600

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/sage_lm_bpe  --no_stop --train_emb --tied --corpus sage --hypes hypes/sage.json --batch_size 6 --bptt_size 600 --proj_head 4 --model_type transformer

# em 0.25; p (0.782, 0.689); r (0.607, 0.444); f1 (0.661, 0.514)
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/pp_test  --no_stop --train_emb --tied --corpus pp --hypes hypes/pp.json --batch_size 10 --proj_head 4 --model_type transformer --inputdir exp/csu_transformer_cut600/model-12.pickle --cut_down_len 600 

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu_transformer_cut600_bpe --no_stop --train_emb --tied --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_transformer_cut600_bpe_pretrainlm --no_stop --train_emb --tied --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --inputdir exp/sage_lm_bpe/model-11.pickle 

#0730

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_transformer_cut600_bpe  --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/csu_lstm_cut600_bpe --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/sage_lm_bpe --corpus sage --hypes hypes/sage.json --batch_size 6 --bptt_size 600 --proj_head 4 --model_type transformer

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu_transformer_cut600_bpe_pretrain_lm  --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --inputdir exp/sage_lm_bpe/model-2.pickle

# 0731

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/pp_test --corpus pp --hypes hypes/pp.json --batch_size 10 --proj_head 4 --cut_down_len 600 --inputdir exp/csu_transformer_cut600_bpe/model-[x].pickle

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_lstm_lockembed --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --init_emb --lm_coef 0.0

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_lstm_unlockembed --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --init_emb --train_emb --lm_coef 0.0

# 0802

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_lstm_no_lm --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --lm_coef 0.0

# 0803

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/sage_lm_lstm_bpe --corpus sage --hypes hypes/sage.json --batch_size 10 --bptt_size 600 --proj_head 4 --model_type lstm --train_emb

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_lstm_cut600 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/csu_transformer_cut600 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu_transformer_cut600_bpe_no_lmloss --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --lm_coef 0.0

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_lstm_cut600_bpe_pretrainlm10 --train_emb --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --inputdir exp/sage_lm_lstm_bpe/model-10.pickle 

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_lstm_cut600_bpe_no_lmloss --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --lm_coef 0.0

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/csu_lstm_cut600_bpe_pretrainedlm10_no_lmloss --corpus csu --hypes hypes/csu.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --lm_coef 0.0 --inputdir exp/sage_lm_lstm_bpe/model-10.pickle 

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu_transformer_cut600_bpe_pretrain_lm8_no_lmloss --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --lm_coef 0.0 --inputdir exp/sage_lm_bpe/model-8.pickle 

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/sage_lm_lstm --corpus sage --hypes hypes/sage_word2vec.json --batch_size 10 --bptt_size 600 --proj_head 4 --model_type lstm --train_emb

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/sage_lm --corpus sage --hypes hypes/sage_word2vec.json --batch_size 5 --bptt_size 600 --proj_head 4 --model_type transformer --train_emb

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/csu_lstm_cut600_pretrainedlm10 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --inputdir exp/sage_lm_lstm/model-10.pickle 

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_lstm_cut600_pretrainedlm10_no_lmloss --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --inputdir exp/sage_lm_lstm/model-10.pickle --lm_coef 0.0 

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_transformer_cut600_pretrainedlm10 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --inputdir exp/sage_lm/model-10.pickle 

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/csu_transformer_cut600_pretrainedlm10_no_lmloss --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --inputdir exp/sage_lm/model-10.pickle --lm_coef 0.0 

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_transformer_cut600_no_lmloss --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --lm_coef 0.0 

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_transformer_cut600_no_lmloss --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --lm_coef 0.0 

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu_lstm_cut600_no_lmloss --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --lm_coef 0.0

# 0805

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/pp_test --corpus pp --hypes hypes/pp.json --batch_size 10 --proj_head 4 --cut_down_len 600 --inputdir exp/bpe/csu_lstm_cut600_bpe_pretrainlm10/model-[x].pickle

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/pp_test --corpus pp --hypes hypes/pp_word2vec.json --batch_size 10 --proj_head 4 --cut_down_len 600 --inputdir exp/csu_transformer_cut600_pretrainedlm10_no_lmloss/model-6.pickle

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_lstm_lockembed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --init_emb --lm_coef 0.0

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_lstm_unlockembed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --init_emb --train_emb --lm_coef 0.0


# 0807
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_transformer_lockembed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --init_emb --lm_coef 0.0

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_transformer_unlockembed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --init_emb --train_emb --lm_coef 0.0

# 0808

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_transformer_cut600_metaloss_1e-4 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --meta_param 0.0001

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_transformer_cut600_metaloss_1e-3 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --meta_param 0.001

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu_transformer_cut600_clusterloss_1e-5_1e-4_1e-4 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cluster_param_a 1e-5 --cluster_param_b 1e-4 --cluster_param_c 1e-4

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/csu_transformer_cut600_clusterloss_1e-4_1e-3_1e-3 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cluster_param_a 1e-4 --cluster_param_b 1e-3 --cluster_param_c 1e-3

# 0810

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/pp--corpus pp --hypes hypes/pp_word2vec.json --batch_size 10 --proj_head 4 --cut_down_len 600 --inputdir exp/csu_transformer_cut600_metaloss_1e-3/model-[x].pickle

# 0811

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_transformer_cut600_pretrainedlm10 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --inputdir exp/sage_lm/model-10.pickle 

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/csu_transformer_cut600_pretrainedlm10_metaloss_1e-2 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --meta_param 1e-2 --inputdir exp/sage_lm/model-10.pickle 

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/csu_transformer_cut600_pretrainedlm10_clusterloss_1e-3_1e-2_1e-2 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cluster_param_a 1e-3 --cluster_param_b 1e-2 --cluster_param_c 1e-2 --inputdir exp/sage_lm/model-10.pickle 

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu_metamap --corpus csu --hypes hypes/csu_word2vec.json --batch_size 20 --cut_down_len 10 --metamap

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/pp_test --corpus pp --hypes hypes/pp_word2vec.json --batch_size 20 --cut_down_len 10 --metamap --inputdir exp/csu_metamap/model-6.pickle

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/test --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cluster_param_a 1e-4 --cluster_param_b 1e-3 --cluster_param_c 1e-3 --inputdir exp/sage_lm/model-10.pickle 

# 0813

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/pp --corpus pp --hypes hypes/pp_word2vec.json --batch_size 10 --proj_head 4 --cut_down_len 600 --inputdir exp/nonbpe/csu_transformer_cut600/model-7.pickle

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/csu --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --cut_down_len 600 --inputdir exp/nonbpe/csu_transformer_cut600/model-7.pickle

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-3_2 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-3 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-3_with_normalization_2 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-3 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/analysis/pp --corpus pp --hypes hypes/pp_word2vec.json --batch_size 10 --proj_head 4 --cut_down_len 600 --inputdir exp/csu_transformer_cut600_pretrainedlm10_clusterloss_1e-3_1e-2_1e-2/model-9.pickle

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_no_projection --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --model_type transformer --cut_down_len 600 --train_emb  

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_projection --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --model_type transformer --cut_down_len 600 --train_emb --proj_head 4 

# 0815 

CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-3_with_normalization --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-3 --cur_epochs 11 --n_epochs 20

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-2_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-2 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-3_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-3 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/analysis/pp --corpus pp --hypes hypes/pp_word2vec.json --batch_size 10 --proj_head 1 --cut_down_len 600 --inputdir exp/csu_transformer_cut600_no_projection/model-6.pickle

# 0816

+ metamap
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_auxiliary_metamap --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --metamap 

+ to decrease em 26.5
CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_auxiliary --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb

+ cooccur loss
CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-3_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-3 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

+ no projection
CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_no_lm_no_projection --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --model_type transformer --cut_down_len 600 --train_emb --lm_coef 0.0

# 0819
CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/analysis/pp --corpus pp --hypes hypes/pp_word2vec.json --batch_size 10 --proj_head 1 --cut_down_len 600 --inputdir exp/csu_transformer_cut600_no_projection/model-6.pickle

+ cooccur loss 1e-4 d
CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-4_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-4 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

+ cooccur loss 1e-3
CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-3_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-3 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

+ cooccur loss 1e-2
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-2_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-2 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

+ to compare projection layer
CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_no_projection --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --model_type transformer --cut_down_len 600 --train_emb

+ no projection
CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_no_lm_no_projection --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --model_type transformer --cut_down_len 600 --train_emb --lm_coef 0.0

+ metamap
CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_metamap --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --metamap --lm_coef 0.0

+ metamap
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_auxiliary_metamap --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --metamap

+ to increase em 23.8
CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

+ to decrease em 26.5
CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_auxiliary --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb

+ lstm metamap
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_metamap --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --metamap --lm_coef 0.0

+ lstm metamap
CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_auxiliary_metamap --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --metamap

+ cooccur loss 1e-4 c
CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_pretrainedlm10_cooccur_loss_1e-4_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --cooccur_param 1e-4 --inputdir exp/nonbpe/sage_lstm/model-10.pickle 


+ cooccur loss 1e-3
CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_pretrainedlm10_cooccur_loss_1e-3_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --cooccur_param 1e-3 --inputdir exp/nonbpe/sage_lstm/model-10.pickle 

+ cooccur loss 1e-2
CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_pretrainedlm10_cooccur_loss_1e-2_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --cooccur_param 1e-2 --inputdir exp/nonbpe/sage_lstm/model-10.pickle 

why lstm metamap takes less memory than vanilla lstm

+ meta
CUDA_VISIBLE_DEVICES=2 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_pretrainedlm10_meta_1e-2 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --meta_param 1e-2 --inputdir exp/nonbpe/sage_lstm/model-10.pickle 

+ cluster
CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_pretrainedlm10_cluster_1e-4_1e-3_1e-3 --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --proj_head 4 --model_type lstm --cut_down_len 600 --train_emb --cluster_param_a 1e-4 --cluster_param_b 1e-3 --cluster_param_c 1e-3 --inputdir exp/nonbpe/sage_lstm/model-10.pickle 

+ to compare projection layer a
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_no_projection --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --model_type lstm --cut_down_len 600 --train_emb

+ no projection b
CUDA_VISIBLE_DEVICES=3 python trainer.py --outputdir exp/hloss/csu_lstm_cut600_no_lm_no_projection --corpus csu --hypes hypes/csu_word2vec.json --batch_size 10 --model_type lstm --cut_down_len 600 --train_emb --lm_coef 0.0

+ cooccur loss 1e-2
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/csu_transformer_cut600_pretrainedlm10_cooccur_loss_1e-2_fixed --corpus csu --hypes hypes/csu_word2vec.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --cooccur_param 1e-2 --inputdir exp/nonbpe/sage_transformer/model-10.pickle 

# non-bpe
CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/transformer_auxiliary_pretrain_bpe_meta_1e-2 --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --inputdir exp/bpe/sage_transformer/model-8.pickle --meta_param 0.01

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/hloss/transformer_auxiliary_pretrain_bpe_cluster_1e-3_1e-2_1e-2 --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --inputdir exp/bpe/sage_transformer/model-8.pickle --cluster_param_a 1e-3 --cluster_param_b 1e-2 --cluster_param_c 1e-2

CUDA_VISIBLE_DEVICES=0 python trainer.py --outputdir exp/hloss/transformer_auxiliary_pretrain_bpe_cooccur_1e-3_glove --corpus csu --hypes hypes/csu.json --batch_size 5 --proj_head 4 --model_type transformer --cut_down_len 600 --train_emb --inputdir exp/bpe/sage_transformer/model-8.pickle --cooccur_param 1e-3

CUDA_VISIBLE_DEVICES=1 python trainer.py --outputdir exp/analysis/pp --corpus pp --hypes hypes/pp.json --batch_size 10 --proj_head 4 --cut_down_len 600 --inputdir exp/csu_transformer_cut600_no_projection/model-6.pickle

# RENAME

➜  bpe git:(master) ✗ mv csu_lstm_cut600_bpe_no_lmloss lstm
➜  bpe git:(master) ✗ mv csu_lstm_cut600_bpe lstm_auxiliary
➜  bpe git:(master) ✗ mv csu_lstm_cut600_bpe_pretrainedlm10_no_lmloss lstm_pretrain
➜  bpe git:(master) ✗ mv csu_lstm_cut600_bpe_pretrainlm10 lstm_auxiliary_pretrain
➜  bpe git:(master) ✗ mv csu_transformer_cut600_bpe_no_lmloss transformer
➜  bpe git:(master) ✗ mv csu_transformer_cut600_bpe transformer_auxiliary
➜  bpe git:(master) ✗ mv csu_transformer_cut600_bpe_pretrain_lm8_no_lmloss transformer_pretrain
➜  bpe git:(master) ✗ mv csu_transformer_cut600_bpe_pretrain_lm8 transformer_auxiliary_pretrain
➜  bpe git:(master) ✗ mv sage_lm_bpe sage_transformer
➜  bpe git:(master) ✗ mv sage_lm_lstm_bpe sage_lstm